{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": "<h2>Segmenting and Clustering Neighborhoods in Toronto Project</h2>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Step 1 is obtaining postal codes from https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M\n\nThis project will use the BeautifulSoup package to scrape the site and convert the data to a dataframe."
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": "# !pip install beautifulsoup4\n# !pip install html5lib"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": "import pandas as pd\nimport numpy as np\nimport requests\nfrom bs4 import BeautifulSoup as bs"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Creating a BeatifulSoup object from an url requires the use of the requests package to return the html document.\nThis is done, and the BeautifulSoup object is imported"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": "url = 'https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M'\nfile=requests.get(url)\ntext=file.text\nsoup=bs(text)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We can use BeautifulSoup find_all of the object type 'table' and save them into table. We can then use read_html from Pandas to turn table into a dataframe. This dataframe is a list of all of the tables, in our case the first table is the one we want and we can save it to our desired \"neigh\" dataframe."
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": "table = soup.find_all('table')\ndf = pd.read_html(str(table))\nneigh=df[0]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Remove the 'not assigned' postal codes "
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": "neigh=neigh[neigh.Borough !='Not assigned']"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "and combining identical postal codes"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": "neigh=neigh.groupby(['Postcode','Borough'], as_index=False).agg({'Neighbourhood':lambda x: ', '.join(x)})"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "and rename any un-named Neighourboods"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "(103, 3)"
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "neigh.loc[(neigh.Neighbourhood=='Not assigned'),'Neighbourhood']=neigh.loc[(neigh.Neighbourhood=='Not assigned'),'Borough']\nneigh.shape"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": "#! pip install geocoder"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": "import geocoder"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Creating a new data frame and adding columns for latitude and longitude"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "neigh_latlng=neigh\nneigh_latlng['Latitude']=\"\"\nneigh_latlng['Longitude']=\"\""
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "I couldn't get the google geocoder service to work right, so I utilized arcgis, it is a bit slow, but works fine."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "for label,row in neigh_latlng.iterrows():\n    neigh_latlng.loc[label,'Latitude'] = geocoder.arcgis(row['Postcode']).latlng[0]\n    neigh_latlng.loc[label,'Longitude'] = geocoder.arcgis(row['Postcode']).latlng[1]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### For the neighborhood clustering, we will follow the same analysis methodology as the New York Lab."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### I continued to use the geocoder library to get the latitude and longitude values of Toronto"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "address = 'Toronto, ON'\n\nlocation = geocoder.arcgis(address)\nlatitude = location.latlng[0]\nlongitude = location.latlng[1]\nprint('The geograpical coordinate of Toronto are {}, {}.'.format(latitude, longitude))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#! pip install folium\nimport folium"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Nearly all of the follow code is taken from the New York lab and modified to suit this exercise"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "As before - let's take a look at all of the neighborhoods"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# create map of Toronoto using latitude and longitude values\nmap_toronto = folium.Map(location=[latitude, longitude], zoom_start=10)\n\n# add markers to map\nfor lat, lng, borough, neighborhood in zip(neigh_latlng['Latitude'], neigh_latlng['Longitude'], neigh_latlng['Borough'], neigh_latlng['Neighbourhood']):\n    label = '{}, {}'.format(neighborhood, borough)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(map_toronto)  \n    \nmap_toronto"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "{\n    \"tags\": [\n        \"hide_input\",\n    ]\n}\n\nCLIENT_ID = 'B252YBG5JPJO0YHRIPXJTFR1YFSLEUGABHOG5IZDB04KEGGT' # your Foursquare ID\nCLIENT_SECRET = '2IYT5VMBXIDT2HDKXSORJILR0JMKUTSIVLEJI30HEUGHS0WU' # your Foursquare Secret\nVERSION = '20180605' # Foursquare API version"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "This function will collect 100 of the closest venues within 500 meters of the postcode centers "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            500, \n            100)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "This calls the above function and saves the data."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_venues = getNearbyVenues(names=neigh_latlng['Neighbourhood'],\n                                   latitudes=neigh_latlng['Latitude'],\n                                   longitudes=neigh_latlng['Longitude']\n                                  )"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "This shows us how many different categories exist in our data set."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print('There are {} uniques categories.'.format(len(toronto_venues['Venue Category'].unique())))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The next three steps will pre-process the data and prepare it for the kmeans clustering algorithim. It converts the 2358 venues into a single row for each post code, depicting the relative frequency of each category."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# one hot encoding\ntoronto_onehot = pd.get_dummies(toronto_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# add neighborhood column back to dataframe\ntoronto_onehot['Neighborhood'] = toronto_venues['Neighborhood'] \n\n# move neighborhood column to the first column\nfixed_columns = [toronto_onehot.columns[-1]] + list(toronto_onehot.columns[:-1])\ntoronto_onehot = toronto_onehot[fixed_columns]\n\ntoronto_onehot.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_onehot.shape"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_grouped = toronto_onehot.groupby('Neighborhood').mean().reset_index()\ntoronto_grouped"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_grouped.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "To simplify the clustering further, the 10 most common venues in each postcode are identified."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "num_top_venues = 10\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Neighborhood']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\nneighborhoods_venues_sorted = pd.DataFrame(columns=columns)\nneighborhoods_venues_sorted['Neighborhood'] = toronto_grouped['Neighborhood']\n\nfor ind in np.arange(toronto_grouped.shape[0]):\n    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(toronto_grouped.iloc[ind, :], num_top_venues)\n\nneighborhoods_venues_sorted"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We can now run our clustering algorithim, kmeans."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.cluster import KMeans"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_grouped_clustering = toronto_grouped.drop('Neighborhood', 1)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "First, we must select the optimum k, or number of clusters. I elected to use the silhoute score to find the best k."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.metrics import silhouette_score\nimport seaborn as sns\nsil = []\nkmax = 15\n\n# dissimilarity would not be defined for a single cluster, thus, minimum number of clusters should be 2\nfor k in range(2, kmax+1):\n  kmeans_k_det = KMeans(n_clusters = k, random_state=0).fit(toronto_grouped_clustering)\n  labels = kmeans_k_det.labels_\n  sil.append(silhouette_score(toronto_grouped_clustering, labels, metric = 'euclidean'))\nx= range(1,15)\nsns.lineplot(x,sil)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We can see that the best value of k is 4, as it produces the highest silhoutte score."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# set number of clusters\nkclusters = 4\n\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(toronto_grouped_clustering)\n\n# check cluster labels generated for each row in the dataframe\nkmeans.labels_[0:10] "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# add clustering labels\nneighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n\ntoronto_merged = neigh_latlng\n\n# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\ntoronto_merged = toronto_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighbourhood')\n\ntoronto_merged # check the last columns!"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "As it turns out, all of the postcodes did not return data. For this exercise, dropping the rows is the best way to deal with missing data."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_merged=toronto_merged.dropna()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We can now take a look at how the clusters appear on a map."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# create map\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(toronto_merged['Latitude'], toronto_merged['Longitude'], toronto_merged['Neighbourhood'], toronto_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[int(cluster-1)],\n        fill=True,\n        fill_color=rainbow[int(cluster-1)],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Finally - we can take a closer look at what each postcode had in common to drive the clustering.\n\nFor example - label '0' appears to contain mainy parks, fields, and farms."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 0, toronto_merged.columns[[2] + list(range(5, toronto_merged.shape[1]))]]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 1, toronto_merged.columns[[2] + list(range(5, toronto_merged.shape[1]))]]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 2, toronto_merged.columns[[2] + list(range(5, toronto_merged.shape[1]))]]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 3, toronto_merged.columns[[2] + list(range(5, toronto_merged.shape[1]))]]"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}